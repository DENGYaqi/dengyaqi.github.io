---
title: Kafka
date: 2025-02-02 10:00:00 +0800
categories: [Kafka]
tags: [kafka]
description: Kafka
pin: true
---

# Kafka

- 全球消息处理性能最快的一款MQ

## 一、为什么使用消息队列

**消息队列解决具体的是什么问题 -> 通信问题**，所以消息队列是一种通信方案。

### 1.使用同步的通信方式来解决多个服务之间的通信

![同步通信的问题](/assets/img/kafka/使用同步的通信方式来解决多个服务之间的通信.png){: width="300" height="300" }
_同步通信流程_

同步的通信方式会存在性能和稳定性的问题。

### 2.使用异步的通信方式

![异步通信的优势与问题](/assets/img/kafka/使用异步的通信方式.png){: width="300" height="300" }
_异步通信流程_

- 下一个订单后直接订单创建成功，将有具体业务信息的请求放置于消息队列中，例如队列1、队列2、队列3。
- 下游的消费者会订阅队列，例如数据库里创建一条订单订阅队列1，给用户加积分订阅队列3。
- 消费成功后，有具体业务信息的请求会到消费者内消费

针对于同步的通信方式来说，异步的方式，可以让上游快速成功，极大提高了系统的吞吐量。而且在分布式系统中，通过下游多个服务的分布式事务的保障，也能保障业务执行之后的最终一致性。

## 二、消息队列的流派

### 1. 什么是 MQ

Message Queue（MQ），消息队列中间件。很多人都说：MQ 通过将消息的发送和接收分离来实现应用程序的异步和解偶，这个给人的直觉是 —- MQ 是异步的，用来解耦的，但是这个只是 MQ 的效果而不是目的。**MQ 真正的目的是为了通讯**，屏蔽底层复杂的通讯协议，定义了一套应用层的、更加简单的通讯协议。一个分布式系统中两个模块之间通讯要么是HTTP，要么是自己开发的（rpc） TCP，但是这两种协议其实都是原始的协议。HTTP协议很难实现两端通讯——模块 A可以调用B， B 也可以主动调用A，如果要做到这个两端都要背上 WebServer，而且还不支持长连接（HTTP 2.0 的库根本找不到）。TCP 就更加原始了，粘包、心跳、私有的协议，想一想头皮就发麻。MQ 所要做的就是在这些协议之上构建一个简单的“协议”——生产者/消费者模型。MQ 带给我的“协议”不是具体的通讯协议，而是更高层次通讯模型。它定义了两个对象——发送数据的叫生产者；接收数据的叫消费者， 提供一个SDK 让我们可以定义自己的生产者和消费者实现消息通讯而无视底层通讯协议
 
### 2. 有broker(中转站)

这个流派通常有一台服务器作为 Broker，所有的消息都通过它中转。生产者把消息发送给它就结束自己的任务了，Broker 则把消息主动推送给消费者（或者消费者主动轮询)

重Topic就是在broker转发的时候以topic作为依据，当我消费者1订阅了主题1，消费者2定义了主题2，那消费者2就收不到主题1的内容了。轻topic可以用topic也可以不用。

- 重Topic : kafka、RocketMQ(阿里)、ActiveMQ

kafka， JMS （ActiveMQ）就属于这个流派，生产者会发送key和数据到Broker，由Broker比较key之后决定给哪个消费者。这种模式是我们最常见的模式，是我们对 MQ 最多的印象。在这种模式下一个topic往往是一个比较大的概念，甚至一个系统中就可能只有一个topic，topic 某种意义上就是 queue，生产者发送 key 相当于说：“hi，把数据放到 key 的队列中”。

如上图所示， Broker定义了三个队列， key1， key2， key3，生产者发送数据的时候会发送key1和data， Broker在推送数据的时候则推送data （也可能把 key带上）。

虽然架构一样但是kafka的性能要比jms的性能不知道高到多少倍，所以基本这种类型的MQ只有kafka一种备选方案。如果你需要一条暴力的数据流（在乎性能而非灵活性）那么 kafka 是最好的选择。

整个broker，依据topic来进行消息的中转。在重topic的消息队列里必然需要topic的存在

- 轻Topic (RabbitMQ)

topic只是一种中转模式。

### 3. 无broker(socket通信)

无 Broker 的 MQ 的代表是 ZeroMQ。该作者非常睿智，他非常敏锐的意识到——MQ 是更高级的 Socket，它是解决通讯问题的。所以ZeroMQ 被设计成了一个“库”而不是一个中间件，这种实现也可以达到——没有 Broker 的目的。

节点之间通讯的消息都是发送到彼此的队列中，每个节点都既是生产者又是消费者。ZeroMQ 做的事情就是***封装出一套类似于 Socket 的API可以完成发送数据，读取数据***

ZeroMQ其实就是一个跨语言的、重量级的Actor 模型邮箱库。你可以把自己的程序想象成一个Actor， ZeroMQ就是提供邮箱功能的库； ZeroMQ可以实现同一台机器的RPC通讯也可以实现不同机器的TCP、UDP通讯，如果你需要一个强大的、灵活、野蛮的通讯能力，别犹豫 ZeroMQ。

### 4. 各种MQ间的区别

- rabbitMQ： 内部的可玩性（功能性）是非常强的
- rocketMQ：阿里内部一个大神，根据kafka的内部执行原理，手写的一个消息队列中间件。性能是与Kafka相比肩，除此之外，在功能上封装了更多的功能。
- kafka:全球消息处理性能最快的一款MQ
- zeroMQ

## 三、Kafka的基本知识

- Kafka介绍

Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica） ，基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、Storm/Spark流式处理引擎， web/nginx日志、访问日志，消息服务等等，用scala语言编写， Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。

- Kafka的使用场景
  - 日志收集：一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。
  - 消息系统：解耦和生产者和消费者、缓存消息等。
  - 用户活动跟踪： Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
  - 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。

### 1.Kafka的安装

- 部署一台zookeeper服务器
- 安装jdk
- 下载kafka的安装包
- 上传到kafka服务器上
- 解压缩压缩包
- 进入到config目录内，修改server.properties
  
  ```shell
  #broker.id属性在kafka集群中必须要是唯一
  broker.id=0

  #kafka部署的机器ip和提供服务的端口号
  listeners=PLAINTEXT://192.168.65.60:9092

  #kafka的消息存储文件
  log.dir=/usr/local/data/kafka-logs

  #kafka连接zookeeper的地址
  zookeeper.connect=192.168.65.60:2181
  ```
  
- 进入到bin目录内，执行以下命令来启动kafka服务器（带着配置文件）

  ```shell
  ./kafka-server-start.sh -daemon ../config/server.properties
  ```
- 校验kafka是否启动成功 : 进入到zk客户端查看是否有kafka的节点`/brokers/ids/0`

以下是具体操作流程。

#### a) 下载与配置

官网下载[2.4.1版本，二进制版本Scala 2.11](https://kafka.apache.org/downloads)，打开终端，进入超级用户模式`sudo -s`，在路径/usr/local/新建kafka文件`mkdir kafka`，解压缩`tar -zxvf kafka_2.11-2.4.1.tgz`，删除压缩包`rm -rf kafka_2.11-2.4.1.tgz`，配置服务器文件`vim server.properties`，使用`ifconfig en0`查看主机地址进行配置，启动zk服务器`./zkServer.sh start ../conf/zoo.cfg`。

项目结构

- bin : 可执行命令。重点关注kafka-server-start.sh。
- config : 配置。重点关注server.properties。

|关键配置|解释|样例|
|:---|:---|:---|
|broker.id|服务器id，必须唯一，需要布置集群的时候每个id是不一样的|broker.id=0|
|listeners|连接到kafka的地址，需要放开，9092是kafka默认的对外提供的端口|listeners = PLAINTEXT://主机地址:9092|
|log.dir|日志存放地址，消息存储文件，默认保存7天|log.dirs=/usr/local/kafka/data/kafka-logs|
|zookeeper.connect|kafka连接到zk的地址，需先启动zk服务器|zookeeper.connect=zk主机地址:2181，查看`../conf/zoo.cfg`文件中的`clientPort`的端口号是否一致，一般zk默认是2181|

为什么要使用zk?

因为broker0，broker1，broker2是kafka的集群，如果需要做到集群无状态，则需要zk，将实际数据保存到zk上。

|其余配置|解释|样例|
|:---|:---|:---|
|log.retention.hours|每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样|168|
|num.partitions|创建topic的默认分区数|1|
|default.replication.factor|自动创建topic的默认副本数量，建议设置为大于等于2|1|
|min.insync.replicas|当producer设置acks为—1时， min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产生异常|1|
|delete.topic.enable|是否允许删除主题|false|

#### b) 启动kafka服务器

进入`/usr/local/kafka/kafka-2.4.1-src/bin`，启动`./kafka-server-start.sh -daemon ../config/server.properties`，检查是否启动成功，查看当前服务器进程是否关联到server.properties配置文件的`ps aux | grep server.properties`(-aux废弃，aux仍可使用，具体查看`man ps`)，显示一大堆信息，启动成功，也可以去zk客户端查看，进入zk客户端`/usr/local/zookeeper/apache-zookeeper-3.7.2-bin/bin`，启动zk客户端`./zkCli.sh`，查看内部数据`ls /`，可以看到多了很多的zk节点，brokers、controller、cluster等等。重点看brokers`ls /brokers`，其子节点是`[ids, seqid, topics]`，再往下看`ls /brokers/ids`，可以看到`[0]`，说明kafka节点为0的服务器上线了。

### 2.kafka中的一些基本概念

kafka是一个分布式的，分区的消息（官方称之为commit log）服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。可以这样来说，Kafka借鉴了JMS规范的思想，但是确并**没有完全遵循JMS规范**。

首先，让我们来看一下基础的消息（Message）相关术语：

|名称|解释|
|:---|:---| 
|Broker|消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群|
|Topic|Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic|
|Producer|消息生产者，向Broker发送消息的客户端|
|Consumer|消息消费者，从Broker读取消息的客户端|
|ConsumerGroup|每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息|
|Partition|物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的|

![基础消息](/assets/img/kafka/基础消息.png){: width="300" height="300" }
_前4个术语的流程_

### 3.创建topic

topic是什么概念？ topic可以实现消息的分类，不同消费者订阅不同的topic。

通过kafka命令向zk中创建一个名为“test”的topic，这个topic只有一个partition，并且备份因子(副本)也设置为1：

```shell
# localhost : zk服务器ip
>>> ./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
Created topic test.
```

查看当前kafka内有哪些topic : 

```shell
# localhost : zk服务器ip
>>> ./kafka-topics.sh --list --zookeeper localhost:2181
test
```

### 4.发送消息

kafka自带了一个producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中。在默认情况下，每一个行会被当做成一个独立的消息。使用kafka的发送消息的客户端，指定发送到的kafka服务器地址和topic

把消息发送给broker中的某个topic，打开kafka的客户端，并开始向kafka服务器发送消息 :

```shell
# localhost : kafka服务器ip
>>> ./kafka-console-producer.sh --broker-list localhost:9092 --topic test
# 输入一条消息abc
> abc
```

### 5.消费消息

对于consumer， kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输出，默认是消费最新的消息。使用kafka的消费者消息的客户端，从指定kafka服务器的指定topic中消费消息。可创建多个终端会话方便查看。

打开一个消费消息的客户端，向kafka服务器的某个主题消费消息 : 

方式一(最新消息)：从最后一条消息的偏移量+1开始消费，执行命令后，可在发送消息的会话窗口输入信息，则可在消费消息的会话窗口看到。

```shell
# localhost : kafka服务器ip
>>> ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test
```

方式二(所有消息)：从头开始消费，只多了一个from beginning指令。

```shell
# localhost : kafka服务器ip
>>> ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic test
```

几个注意点：

- 消息会被存储
- 消息是顺序存储
- 消息是有偏移量的
- 消费时可以指明偏移量进行消费

### 6.关于消息的细节

- 生产者将消息发送给broker， broker会将消息保存在本地的日志文件中`/usr/local/kafka/data/kafka-logs/主题-分区/00000000.log`
- 消息的保存是有序的，通过offset偏移量来描述消息的有序性
- 消费者消费消息时也是通过offset来描述当前要消费的那条消息的位置

### 7.单播消息 (同一组只有一个)

如果多个消费者在同一个消费组，那么只有一个消费者可以收到订阅的topic中的消息。换言之，同一个消费组中只能有一个消费者收到一个topic中的消息。

配置消费组 : --consumer-property group.id=testGroup

```shell
# localhost : kafka服务器ip
>>> ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup --topic test
```

### 8.多播消息 (不同组中只有一个)

不同的消费组订阅同一个topic，那么不同的消费组中只有一个消费者能收到消息。实际上也是多个消费组中的多个消费者收到了同一个消息。

```shell
# localhost : kafka服务器ip
>>> ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup1 --topic test
>>> ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup2 --topic test
```

![单播和多播](/assets/img/kafka/单播和多播.png){: width="300" height="300" }
_单播和多播的区别_

### 9. 查看消费组的详细信息

```shell
# 查看当前主题下有哪些消费组
./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

# 查看消费组中的具体信息：比如当前偏移量、最后一条消息的偏移量、堆积的消息数量
./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup
```

|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|GROUP|TOPIC|PARTITION|CURRENT-OFFSET(当前偏移量)|LOG-END-OFFSET(已消费的偏移量)|LAG(剩余多少条消息未被消费)|CONSUMER-ID(消费者id)|HOST(主机信息)|CLIENT-ID(客户端信息)|
|testGroup|test|0|9|9|0|-|-|-|

## 四、Kafka中主题和分区的概念

### 1. 主题Topic

### 2. 分区Partition

- 1) 分区的概念

- 2) 创建多分区的主题

### 3. kafka中消息日志文件中保存的内容

## 五、Kafka集群操作

### 1. 搭建kafka集群(三个broker)

### 2 .副本的概念

### 3. 关于集群消费

- 1) 向集群发送消息

- 2) 从集群中消费消息

- 3) 指定消费组来消费消息

- 4) 分区分消费组的集群消费中的细节

## 六、Kafka的java客户端-生产者的实现

### 1. 生产者的基本实现

### 2. 生产者的同步发送消息

### 3. 生产者的异步发送消息

### 4. 生产者中的ack的配置

### 5. 关于消息发送的缓冲区

## 十一、Kafka—eagle监控平台

### 1.搭建

### 2.平台的使用

## 十、Kafka中的优化问题

### 1.如何防止消息丢失

### 2.如何防止重复消费

### 3.如何做到消息的顺序消费

### 4.如何解决消息积压问题

- 1) 消息积压问题的出现

- 2) 消息积压的解决方案

### 5.实现延时队列的效果

- 1) 应用场景

- 2) 具体方案

## 九、Kafka集群中的controller、rebalance、HW

### 1.controller

### 2.rebalance机制

### 3.HW和LEO

## 八、Springboot中使用Kafka

### 1.引入依赖

### 2.编写配置文件

### 3.编写消息生产者

### 4.编写消费者

### 5.消费者中配置消费主题、分区和偏移量

## 七、Java客户端消费者的实现细节

### 1.消费者的基本实现

### 2.关于消费者自动提交和手动提交offset

- 1) 提交的内容

- 2) 自动提交

- 3) 手动提交

### 3.长轮询poll消息

### 4.消费者的健康状态检查

### 5.指定分区和偏移量、时间消费

### 6.新消费组的消费offset规则
